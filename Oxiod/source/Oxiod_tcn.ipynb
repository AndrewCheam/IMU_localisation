{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7927fbb-79ca-4fb3-a38c-b11ba41a72bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://192.168.16.2:8080/root/pypi/+simple/, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.6.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n",
      "Requirement already satisfied: protobuf>=4.22.3 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (4.23.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.22.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://192.168.16.2:8080/root/pypi/+simple/, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: numpy-quaternion in /usr/local/lib/python3.8/dist-packages (2022.4.3)\n",
      "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.8/dist-packages (from numpy-quaternion) (1.22.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://192.168.16.2:8080/root/pypi/+simple/, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.22.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "! pip install tensorboardX\n",
    "! pip install numpy-quaternion\n",
    "! pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df3e435-b649-4f4f-981c-bf7883f5038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from os import path as osp\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from model_temporal import LSTMSeqNetwork, BilinearLSTMSeqNetwork, TCNSeqNetwork\n",
    "from utils import load_config, MSEAverageMeter\n",
    "from data_Oxiod import *\n",
    "from transformations import ComposeTransform, RandomHoriRotateSeq\n",
    "from metric import compute_absolute_trajectory_error, compute_relative_trajectory_error\n",
    "\n",
    "# torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "# _nano_to_sec = 1e09\n",
    "# device = 'cpu'\n",
    "global _input_channel, _output_channel\n",
    "_input_channel, _output_channel = 6, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b7baa8-0edb-4275-b502-be281ea79aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "\n",
    "#Paths to different files\n",
    "args.type = 'tcn' #choices=['tcn', 'lstm', 'lstm_bi']\n",
    "args.root_dir = '/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset/handheld'\n",
    "args.train_list = osp.join(args.root_dir, 'Train-small.txt')\n",
    "args.val_list = osp.join(args.root_dir, 'Validation.txt')\n",
    "args.test_list = osp.join(args.root_dir, 'Test.txt')\n",
    "args.out_dir = osp.join(args.root_dir, args.type + '_outputs')\n",
    "args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "\n",
    "\n",
    "\n",
    "args.test_path = None\n",
    "args.cache_path = None\n",
    "args.continue_from = None\n",
    "args.transfer_from = None\n",
    "\n",
    "\n",
    "# Params to tune for neural network\n",
    "args.mode = \"train\"\n",
    "args.step_size = 10\n",
    "args.window_size = 400\n",
    "args.lr = 1e-04\n",
    "args.batch_size = 256\n",
    "args.epochs = 80\n",
    "args.freeze_params = False\n",
    "args.save_interval = 20\n",
    "\n",
    "# # tcn\n",
    "args.kernel_size = 3\n",
    "args.channels = [32,64,128,256,72,36]\n",
    "# # lstm\n",
    "args.layers = 3\n",
    "args.layer_size = 100\n",
    "\n",
    "args.cpu = False\n",
    "args.device = torch.device('cuda:0' if torch.cuda.is_available() and not args.cpu else 'cpu')\n",
    "args.run_ekf = False\n",
    "args.fast_test = False\n",
    "\n",
    "# Plots and animation\n",
    "args.show_plot = True\n",
    "args.saveAnim = False\n",
    "\n",
    "# Smoothing feature and targets\n",
    "args.feature_sigma = 2\n",
    "args.target_sigma = 2\n",
    "\n",
    "np.set_printoptions(formatter={'all': lambda x: '{:.6f}'.format(x)})\n",
    "\n",
    "def get_model(args, **kwargs):\n",
    "    config = {}\n",
    "    if kwargs.get('dropout'):\n",
    "        config['dropout'] = kwargs.get('dropout')\n",
    "\n",
    "    if args.type == 'tcn':\n",
    "        network = TCNSeqNetwork(_input_channel, _output_channel, args.kernel_size,\n",
    "                                layer_channels=args.channels, **config)\n",
    "        print(\"TCN Network. Receptive field: {} \".format(network.get_receptive_field()))\n",
    "    elif args.type == 'lstm_bi':\n",
    "        print(\"Bilinear LSTM Network\")\n",
    "        network = BilinearLSTMSeqNetwork(_input_channel, _output_channel, args.batch_size, device,\n",
    "                                         lstm_layers=args.layers, lstm_size=args.layer_size, **config).to(device)\n",
    "    else:\n",
    "        print(\"Simple LSTM Network\")\n",
    "        network = LSTMSeqNetwork(_input_channel, _output_channel, args.batch_size, device,\n",
    "                                 lstm_layers=args.layers, lstm_size=args.layer_size, **config).to(device)\n",
    "\n",
    "    pytorch_total_params = sum(p.numel() for p in network.parameters() if p.requires_grad)\n",
    "    print('Network constructed. trainable parameters: {}'.format(pytorch_total_params))\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd7eec5-4c0c-4080-821d-e8b2e2725a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalPosLoss(torch.nn.Module):\n",
    "    def __init__(self, mode='full', history=None):\n",
    "        \"\"\"\n",
    "        Calculate position loss in global coordinate frame\n",
    "        Target :- Global Velocity\n",
    "        Prediction :- Global Velocity\n",
    "        \"\"\"\n",
    "        super(GlobalPosLoss, self).__init__()\n",
    "        self.mse_loss = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "        assert mode in ['full', 'part']\n",
    "        self.mode = mode\n",
    "        if self.mode == 'part':\n",
    "            assert history is not None\n",
    "            self.history = history\n",
    "        elif self.mode == 'full':\n",
    "            self.history = 1\n",
    "\n",
    "    # shape = [num_dimensions, sequence_length]\n",
    "    def forward(self, pred, targ):\n",
    "        gt_pos = torch.cumsum(targ[:, 1:, ], 1)\n",
    "        pred_pos = torch.cumsum(pred[:, 1:, ], 1)\n",
    "        if self.mode == 'part':\n",
    "            gt_pos = gt_pos[:, self.history:, :] - gt_pos[:, :-self.history, :]\n",
    "            pred_pos = pred_pos[:, self.history:, :] - pred_pos[:, :-self.history, :]\n",
    "        loss = self.mse_loss(pred_pos, gt_pos)\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e7158e-ad98-4253-b636-dc289e12982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_config(args, **kwargs):\n",
    "    if args.out_dir:\n",
    "        with open(osp.join(args.out_dir, 'config.json'), 'w') as f:\n",
    "            values = vars(args)\n",
    "            values['file'] = \"pytorch_global_position\"\n",
    "            if kwargs:\n",
    "                values['kwargs'] = kwargs\n",
    "            json.dump(values, f, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67343bf1-9359-4d1b-b9c6-ef70f2ec7d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(root_dir, data_list, args, **kwargs):\n",
    "    global _output_channel\n",
    "    input_format, output_format = [0, 3, 6], [0, _output_channel]\n",
    "    mode = kwargs.get('mode', 'train')\n",
    "\n",
    "    random_shift, shuffle, transforms, grv_only = 0, False, [], False\n",
    "    if mode == 'train':\n",
    "        args.feature_sigma = 2\n",
    "        args.target_sigma = 2\n",
    "        random_shift = args.step_size // 2\n",
    "        shuffle = True\n",
    "        transforms.append(RandomHoriRotateSeq(input_format, output_format))\n",
    "    elif mode == 'val':\n",
    "        shuffle = True\n",
    "        args.feature_sigma = -1\n",
    "        args.target_sigma = -1\n",
    "    elif mode == 'test':\n",
    "        shuffle = False\n",
    "        grv_only = True\n",
    "        args.feature_sigma = -1\n",
    "        args.target_sigma = -1\n",
    "    transforms = ComposeTransform(transforms)\n",
    "    \n",
    "    seq_type = OxfordGlobSpeedSequence\n",
    "    print('Parameters into dataset initialisation \\n feat_sigma: {}, targ_sigma: {}, random_shift: {}, transform: {}'.format(args.feature_sigma, args.target_sigma, random_shift, transforms))\n",
    "    dataset = SequenceToSequenceDataset(seq_type, root_dir, data_list, args.cache_path, args.step_size, args.window_size, shuffle = shuffle, \n",
    "                                     grv_only=grv_only, transform = None, random_shift = random_shift, feature_sigma = args.feature_sigma, target_sigma = args.target_sigma)\n",
    "    print(f'step_size: {dataset.step_size}, window_size: {dataset.window_size}')\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_dataset_from_list(root_dir, list_path, args, **kwargs):\n",
    "    with open(list_path) as f:\n",
    "        data_list = [s.strip().split(',' or ' ')[0] for s in f.readlines() if len(s) > 0 and s[0] != '#']\n",
    "    return get_dataset(root_dir, data_list, args, **kwargs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d7e1347-7b35-47d5-8e65-c2b695554e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_function(history, args, **kwargs):\n",
    "    if args.type == 'tcn':\n",
    "        config = {'mode': 'part',\n",
    "                  'history': history}\n",
    "    else:\n",
    "        config = {'mode': 'full'}\n",
    "\n",
    "    criterion = GlobalPosLoss(**config)\n",
    "    return criterion\n",
    "\n",
    "\n",
    "def format_string(*argv, sep=' '):\n",
    "    result = ''\n",
    "    for val in argv:\n",
    "        if isinstance(val, (tuple, list, np.ndarray)):\n",
    "            for v in val:\n",
    "                result += format_string(v, sep=sep) + sep\n",
    "        else:\n",
    "            result += str(val) + sep\n",
    "    return result[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91cf768f-f37f-4207-8051-fb0a6a46f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, **kwargs):\n",
    "    # Loading data\n",
    "    start_t = time.time()\n",
    "    train_dataset = get_dataset_from_list(args.root_dir, args.train_list, args, mode='train', **kwargs)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "    end_t = time.time()\n",
    "\n",
    "    print('Training set loaded. Time usage: {:.3f}s'.format(end_t - start_t))\n",
    "    val_dataset, val_loader = None, None\n",
    "    if args.val_list is not None:\n",
    "        val_dataset = get_dataset_from_list(args.root_dir, args.val_list, args, mode='val', **kwargs)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "        print('Validation set loaded')\n",
    "\n",
    "    global device\n",
    "    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    \n",
    "    if args.out_dir is not None:\n",
    "        if not osp.isdir(args.out_dir):\n",
    "            os.makedirs(args.out_dir)\n",
    "        #write_config(args)\n",
    "            \n",
    "        if not osp.isdir(osp.join(args.out_dir, 'checkpoints')):\n",
    "            os.makedirs(osp.join(args.out_dir, 'checkpoints'))\n",
    "        if not osp.isdir(osp.join(args.out_dir, 'logs')):\n",
    "            os.makedirs(osp.join(args.out_dir, 'logs'))\n",
    "\n",
    "    print('\\nNumber of train samples: {}'.format(len(train_dataset)))\n",
    "    train_mini_batches = len(train_loader)\n",
    "    if val_dataset:\n",
    "        print('Number of val samples: {}'.format(len(val_dataset)))\n",
    "        val_mini_batches = len(val_loader)\n",
    "\n",
    "    network = get_model(args, **kwargs).to(device)\n",
    "    history = network.get_receptive_field() if args.type == 'tcn' else args.window_size // 2\n",
    "    criterion = get_loss_function(history, args, **kwargs)\n",
    "\n",
    "    optimizer = torch.optim.Adam(network.parameters(), args.lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.75, verbose=True, eps=1e-12)\n",
    "    quiet_mode = False\n",
    "    use_scheduler = kwargs.get('use_scheduler', False)\n",
    "\n",
    "    log_file = None\n",
    "    if args.out_dir:\n",
    "        log_file = osp.join(args.out_dir, 'logs', 'log.txt')\n",
    "        if osp.exists(log_file):\n",
    "            if args.continue_from is None:\n",
    "                os.remove(log_file)\n",
    "            else:\n",
    "                copyfile(log_file, osp.join(args.out_dir, 'logs', 'log_old.txt'))\n",
    "\n",
    "    start_epoch = 0\n",
    "    train_losses_all, val_losses_all = [], []\n",
    "#     if args.continue_from is not None and osp.exists(args.continue_from):\n",
    "#         with open(osp.join(str(Path(args.continue_from).parents[1]), 'config.json'), 'r') as f:\n",
    "#             model_data = json.load(f)\n",
    "\n",
    "#         if device.type == 'cpu':\n",
    "#             checkpoints = torch.load(args.continue_from, map_location=lambda storage, location: storage)\n",
    "#         else:\n",
    "#             checkpoints = torch.load(args.continue_from, map_location={model_data['device']: args.device})\n",
    "\n",
    "#         start_epoch = checkpoints.get('epoch', 0)\n",
    "#         network.load_state_dict(checkpoints.get('model_state_dict'))\n",
    "#         optimizer.load_state_dict(checkpoints.get('optimizer_state_dict'))\n",
    "    if kwargs.get('force_lr', False):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = args.lr\n",
    "\n",
    "    step = 0\n",
    "    best_val_loss = np.inf\n",
    "    train_errs = np.zeros(args.epochs)\n",
    "\n",
    "    print(\"Starting from epoch {}\".format(start_epoch))\n",
    "    try:\n",
    "        for epoch in range(start_epoch, args.epochs):\n",
    "            log_line = ''\n",
    "            network.train()\n",
    "            train_vel = MSEAverageMeter(3, [2], _output_channel)\n",
    "            train_loss = 0\n",
    "            start_t = time.time()\n",
    "\n",
    "            for bid, batch in enumerate(train_loader):\n",
    "                feat, targ, _, _ = batch\n",
    "                feat, targ = feat.to(device), targ.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                predicted = network(feat)\n",
    "                train_vel.add(predicted.cpu().detach().numpy(), targ.cpu().detach().numpy())\n",
    "                loss = criterion(predicted, targ)\n",
    "                train_loss += loss.cpu().detach().numpy()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                step += 1\n",
    "\n",
    "            train_errs[epoch] = train_loss / train_mini_batches\n",
    "            train_losses_all.append(train_loss / train_mini_batches)\n",
    "            end_t = time.time()\n",
    "            if not quiet_mode:\n",
    "                print('-' * 25)\n",
    "                print('Epoch {}, time usage: {:.3f}s, loss: {}, vel_loss {}/{:.6f}'.format(\n",
    "                    epoch, end_t - start_t, train_errs[epoch], train_vel.get_channel_avg(), train_vel.get_total_avg()))\n",
    "            log_line = format_string(log_line, epoch, optimizer.param_groups[0]['lr'], train_errs[epoch],\n",
    "                                     *train_vel.get_channel_avg())\n",
    "\n",
    "            saved_model = False\n",
    "            if val_loader:\n",
    "                network.eval()\n",
    "                val_vel = MSEAverageMeter(3, [2], _output_channel)\n",
    "                val_loss = 0\n",
    "                for bid, batch in enumerate(val_loader):\n",
    "                    feat, targ, _, _ = batch\n",
    "                    feat, targ = feat.to(device), targ.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = network(feat)\n",
    "                    val_vel.add(pred.cpu().detach().numpy(), targ.cpu().detach().numpy())\n",
    "                    val_loss += criterion(pred, targ).cpu().detach().numpy()\n",
    "                val_loss = val_loss / val_mini_batches\n",
    "                val_losses_all.append(val_loss / val_mini_batches)\n",
    "                log_line = format_string(log_line, val_loss, *val_vel.get_channel_avg())\n",
    "                if not quiet_mode:\n",
    "                    print('Validation loss: {} vel_loss: {}/{:.6f}'.format(val_loss, val_vel.get_channel_avg(),\n",
    "                                                                           val_vel.get_total_avg()))\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    saved_model = True\n",
    "                    if args.out_dir:\n",
    "                        model_path = osp.join(args.out_dir, 'checkpoints', 'checkpoint_%d.pt' % epoch)\n",
    "                        torch.save({'model_state_dict': network.state_dict(),\n",
    "                                    'epoch': epoch,\n",
    "                                    'loss': train_errs[epoch],\n",
    "                                    'optimizer_state_dict': optimizer.state_dict()}, model_path)\n",
    "                        print('Best Validation Model saved to ', model_path)\n",
    "                if use_scheduler:\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "            if args.out_dir and not saved_model and (epoch + 1) % args.save_interval == 0:  # save even with validation\n",
    "                model_path = osp.join(args.out_dir, 'checkpoints', 'icheckpoint_%d.pt' % epoch)\n",
    "                torch.save({'model_state_dict': network.state_dict(),\n",
    "                            'epoch': epoch,\n",
    "                            'loss': train_errs[epoch],\n",
    "                            'optimizer_state_dict': optimizer.state_dict()}, model_path)\n",
    "                print('Model saved to ', model_path)\n",
    "\n",
    "            if log_file:\n",
    "                log_line += '\\n'\n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(log_line)\n",
    "            if np.isnan(train_loss):\n",
    "                print(\"Invalid value. Stopping training.\")\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('-' * 60)\n",
    "        print('Early terminate')\n",
    "\n",
    "    print('Training completed')\n",
    "    if args.out_dir:\n",
    "        model_path = osp.join(args.out_dir, 'checkpoints', 'checkpoint_latest.pt')\n",
    "        torch.save({'model_state_dict': network.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'optimizer_state_dict': optimizer.state_dict()}, model_path)\n",
    "    return train_losses_all, val_losses_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78ad39e-95fd-4a7a-b3f3-eaaa1a7c1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_traj_with_preds_global(dataset, preds, ind=None, seq_id=0, type='preds', **kwargs):\n",
    "    ind = ind if ind is not None else np.array([i[1] for i in dataset.index_map if i[0] == seq_id], dtype=np.int)\n",
    "\n",
    "    if type == 'gt':\n",
    "        pos = dataset.gt_pos[seq_id][:, :2]\n",
    "    else:\n",
    "        ts = dataset.ts[seq_id]\n",
    "        # Compute the global velocity from local velocity.\n",
    "        dts = np.mean(ts[ind[1:]] - ts[ind[:-1]])\n",
    "        pos = preds * dts\n",
    "        pos[0, :] = dataset.gt_pos[seq_id][0, :2]\n",
    "        pos = np.cumsum(pos, axis=0)\n",
    "    veloc = preds\n",
    "    ori = dataset.orientations[seq_id]\n",
    "\n",
    "    return pos, veloc, ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6adcac72-64a0-4bda-9e3b-0a67727b1baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def showAnimation(video_path):\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    video_widget = widgets.Video.from_file(video_path)\n",
    "    video_widget.controls = True\n",
    "    video_widget.autoplay = True\n",
    "    display(video_widget)\n",
    "\n",
    "def plotTrajectory(true_x_values, true_y_values, pred_x_values, pred_y_values):    \n",
    "    plt.figure('{}'.format(\"Trajectory\"), figsize=(16, 9))\n",
    "\n",
    "    length = len(true_x_values)\n",
    "    multiplier = 50\n",
    "    # creating a blank window\n",
    "    # for the animation\n",
    "    fig = plt.figure()\n",
    "    min_x_value = np.min([np.min(true_x_values), np.min(pred_x_values)])\n",
    "    max_x_value = np.max([np.max(true_x_values), np.max(pred_x_values)])\n",
    "    min_y_value = np.min([np.min(true_y_values), np.min(pred_y_values)])\n",
    "    max_y_value = np.max([np.max(true_y_values), np.max(pred_y_values)])\n",
    "    \n",
    "    \n",
    "    axis = plt.axes(xlim =(min_x_value, max_x_value), ylim =(min_y_value, max_y_value))\n",
    "    \n",
    "    line1, = axis.plot([], [], 'b', label='Line 1')\n",
    "    line2, = axis.plot([], [], 'r', label='Line 2')\n",
    "\n",
    "    def init():\n",
    "        line1.set_data([], [])\n",
    "        return line1,\n",
    "    def init():\n",
    "        line2.set_data([], [])\n",
    "        return line2,\n",
    "\n",
    "    # initializing empty values\n",
    "    # for x and y co-ordinates\n",
    "    true_xdata, true_ydata, pred_xdata, pred_ydata = [], [], [], []\n",
    "\n",
    "    # animation function\n",
    "    def animate(i):\n",
    "        true_x = true_x_values[i * multiplier]\n",
    "        true_y = true_y_values[i * multiplier]\n",
    "        pred_x = pred_x_values[i * multiplier]\n",
    "        pred_y = pred_y_values[i * multiplier]\n",
    "        \n",
    "        true_xdata.append(true_x)\n",
    "        true_ydata.append(true_y)\n",
    "        pred_xdata.append(pred_x)\n",
    "        pred_ydata.append(pred_y)\n",
    "        \n",
    "        line1.set_data(true_xdata, true_ydata)\n",
    "        line2.set_data(pred_xdata, pred_ydata)\n",
    "\n",
    "        return line1, line2\n",
    "\n",
    "    # calling the animation function\t\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func = init, frames = int(length/multiplier), interval = 0.01, blit = True)\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f3d029-1a20-49b4-888b-e5f69370e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, **kwargs):\n",
    "    global device, _output_channel\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if args.test_path is not None:\n",
    "        if args.test_path[-1] == '/':\n",
    "            args.test_path = args.test_path[:-1]\n",
    "        root_dir = osp.split(args.test_path)[0]\n",
    "        test_data_list = [osp.split(args.test_path)[1]]\n",
    "    elif args.test_list is not None:\n",
    "        root_dir = args.root_dir if args.root_dir else osp.split(args.test_list)[0]\n",
    "        with open(args.test_list) as f:\n",
    "            test_data_list = [s.strip().split(',')[0] for s in f.readlines() if len(s) > 0 and s[0] != '#']\n",
    "    else:\n",
    "        raise ValueError('Either test_path or test_list must be specified.')\n",
    "\n",
    "    # Load the first sequence to update the input and output size\n",
    "    _ = get_dataset(root_dir, [test_data_list[0]], args, mode='test')\n",
    "\n",
    "    if args.out_dir and not osp.exists(args.out_dir):\n",
    "        os.makedirs(args.out_dir)\n",
    "        \n",
    "    if not osp.isdir(osp.join(args.out_dir, 'Videos')) or not osp.isdir(osp.join(args.out_dir, 'Graphs')):\n",
    "        os.makedirs(osp.join(args.out_dir, 'Videos'))\n",
    "        os.makedirs(osp.join(args.out_dir, 'Graphs'))\n",
    "    \n",
    "    checkpoint = torch.load(args.model_path)\n",
    "    network = get_model(args, **kwargs)\n",
    "    network.load_state_dict(checkpoint.get('model_state_dict'))\n",
    "    network.eval().to(device)\n",
    "    print('Model {} loaded to device {}.'.format(args.model_path, device))\n",
    "\n",
    "    # log_file = None\n",
    "    # if args.test_list and args.out_dir:\n",
    "    #     log_file = osp.join(args.out_dir, osp.split(args.test_list)[-1].split('.')[0] + '_log.txt')\n",
    "    #     with open(log_file, 'w') as f:\n",
    "    #         f.write(args.model_path + '\\n')\n",
    "    #         f.write('Seq traj_len velocity ate rte\\n')\n",
    "\n",
    "    losses_vel = MSEAverageMeter(2, [1], _output_channel)\n",
    "    ate_all, rte_all = [], []\n",
    "    pred_per_min = 200 * 60\n",
    "\n",
    "    seq_dataset = get_dataset(root_dir, test_data_list, args, mode='test', **kwargs)\n",
    "\n",
    "    for idx, data in enumerate(test_data_list):\n",
    "        #assert data == osp.split(seq_dataset.data_path[idx])[1]\n",
    "        print(network)\n",
    "        feat, vel = seq_dataset.get_test_seq(idx)\n",
    "        feat = torch.Tensor(feat).to(device)\n",
    "        preds = np.squeeze(network(feat).cpu().detach().numpy())[-vel.shape[0]:, :_output_channel]\n",
    "        \n",
    "        ind = np.arange(vel.shape[0])\n",
    "        vel_losses = np.mean((vel - preds) ** 2, axis=0)\n",
    "        losses_vel.add(vel, preds)\n",
    "\n",
    "        print('Reconstructing trajectory')\n",
    "        pos_pred, gv_pred, _ = recon_traj_with_preds_global(seq_dataset, preds, ind=ind, type='pred', seq_id=idx)\n",
    "        pos_gt, gv_gt, _ = recon_traj_with_preds_global(seq_dataset, vel, ind=ind, type='gt', seq_id=idx)\n",
    "\n",
    "        \n",
    "\n",
    "        ate = compute_absolute_trajectory_error(pos_pred, pos_gt)\n",
    "        if pos_pred.shape[0] < pred_per_min:\n",
    "            ratio = pred_per_min / pos_pred.shape[0]\n",
    "            rte = compute_relative_trajectory_error(pos_pred, pos_gt, delta=pos_pred.shape[0] - 1) * ratio\n",
    "        else:\n",
    "            rte = compute_relative_trajectory_error(pos_pred, pos_gt, delta=pred_per_min)\n",
    "        pos_cum_error = np.linalg.norm(pos_pred - pos_gt, axis=1)\n",
    "        ate_all.append(ate)\n",
    "        rte_all.append(rte)\n",
    "\n",
    "        print('Sequence {}, Velocity loss {} / {}, ATE: {}, RTE:{}'.format(data, vel_losses, np.mean(vel_losses), ate,\n",
    "                                                                           rte))\n",
    "        log_line = format_string(data, np.mean(vel_losses), ate, rte)\n",
    "\n",
    "        kp = 2\n",
    "        targ_names = ['vx', 'vy']\n",
    "\n",
    "        if args.out_dir is not None and osp.isdir(args.out_dir) and args.saveAnim:\n",
    "            video_path = osp.join(args.out_dir, 'Videos/' + ''.join(data.split('/')) +'_Trajectory.mp4')\n",
    "            animation = plotTrajectory(pos_gt[:, 0], pos_gt[:, 1], pos_pred[:, 0], pos_pred[:, 1])\n",
    "            animation.save(video_path, writer = 'ffmpeg', fps = 50, bitrate = 700)\n",
    "            showAnimation(video_path)\n",
    "            \n",
    "        plt.figure('{}'.format(data), figsize=(16, 9))\n",
    "        plt.subplot2grid((kp, 2), (0, 0), rowspan=kp - 1)\n",
    "        plt.plot(pos_pred[:, 0], pos_pred[:, 1])\n",
    "        plt.plot(pos_gt[:, 0], pos_gt[:, 1])\n",
    "        plt.title(data)\n",
    "        plt.axis('equal')\n",
    "        plt.legend(['Predicted', 'Ground truth'])\n",
    "        plt.subplot2grid((kp, 2), (kp - 1, 0))\n",
    "        plt.plot(pos_cum_error)\n",
    "        plt.legend(['ATE:{:.3f}, RTE:{:.3f}'.format(ate_all[-1], rte_all[-1])])\n",
    "        for i in range(kp):\n",
    "            plt.subplot2grid((kp, 2), (i, 1))\n",
    "            plt.plot(ind, preds[:, i])\n",
    "            plt.plot(ind, vel[:, i])\n",
    "            plt.legend(['Predicted', 'Ground truth'])\n",
    "            plt.title('{}, error: {:.6f}'.format(targ_names[i], vel_losses[i]))\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if args.out_dir is not None and osp.isdir(args.out_dir):\n",
    "            np.save(osp.join(args.out_dir, 'Graphs/'+''.join(data.split('/')) + '_gsn.npy'),\n",
    "                    np.concatenate([pos_pred[:, :2], pos_gt[:, :2]], axis=1))\n",
    "            plt.savefig(osp.join(args.out_dir, 'Graphs/'+''.join(data.split('/')) + '_gsn.png'))\n",
    "            \n",
    "        if args.show_plot:\n",
    "            plt.show()\n",
    "\n",
    "        # if args.out_dir is not None and osp.isdir(args.out_dir):\n",
    "        #     np.save(osp.join(args.out_dir, '{}_{}.npy'.format(data, args.type)),\n",
    "        #             np.concatenate([pos_pred, pos_gt], axis=1))\n",
    "        # if args.out_dir is not None and osp.isdir(args.out_dir):\n",
    "        #     plt.savefig(osp.join(args.out_dir, '{}_{}.png'.format(data, args.type)))\n",
    "        plt.close('all')\n",
    "\n",
    "    ate_all = np.array(ate_all)\n",
    "    rte_all = np.array(rte_all)\n",
    "\n",
    "    measure = format_string('ATE', 'RTE', sep='\\t')\n",
    "    values = format_string(np.mean(ate_all), np.mean(rte_all), sep='\\t')\n",
    "    print(measure, '\\n', values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688bdad-7926-4966-aa05-8f2f53c95acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters into dataset initialisation \n",
      " feat_sigma: 2, targ_sigma: 2, random_shift: 5, transform: <transformations.ComposeTransform object at 0x7f14900dbf40>\n",
      "Parameters in dataset \n",
      "feat_sigma: 2, targ_sigma: 2, random_shift: 5, transform: None\n",
      "step_size: 10, window_size: 400\n",
      "Training set loaded. Time usage: 1.676s\n",
      "Parameters into dataset initialisation \n",
      " feat_sigma: -1, targ_sigma: -1, random_shift: 0, transform: <transformations.ComposeTransform object at 0x7f14703b23a0>\n",
      "Parameters in dataset \n",
      "feat_sigma: -1, targ_sigma: -1, random_shift: 0, transform: None\n",
      "step_size: 10, window_size: 400\n",
      "Validation set loaded\n",
      "\n",
      "Number of train samples: 49880\n",
      "Number of val samples: 10536\n",
      "TCN Network. Receptive field: 253 \n",
      "Network constructed. trainable parameters: 540488\n",
      "Starting from epoch 0\n"
     ]
    }
   ],
   "source": [
    "#data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "data_path_list = ['handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "i = 1\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "fig.tight_layout()\n",
    "for data in data_path_list:\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.train_list = osp.join(args.root_dir, 'Train.txt')\n",
    "    args.val_list = osp.join(args.root_dir, 'Validation.txt')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "    args.out_dir = osp.join(args.root_dir, args.type + '_outputs')\n",
    "    train_losses, val_losses = train(args)\n",
    "    plt.subplot(math.ceil(len(data_path_list) / 2), 2 , i)\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.title(data+' training loss')\n",
    "    plt.legend(['train_loss', 'val_loss'])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef679dc-a9a6-4d07-923b-9d17c5452505",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.saveAnim = False\n",
    "args.batch_size = 1\n",
    "args.target_sigma = -1\n",
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "for data in data_path_list:\n",
    "    print(f'=============================================================================outputs for {data} ==============================================================')\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.test_list = osp.join(args.root_dir, 'Test.txt')\n",
    "    args.out_dir = osp.join(args.root_dir, args.type + '_outputs')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "    test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee016485-de20-4292-852f-55ae189e368d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ee62f-0761-4f67-bf23-ff08030c94b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae3718-0ca2-46f5-906c-9f328b5812a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c5d131-a273-4f91-9270-52a777197ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40aa56e-4dee-46ed-b76f-41391993e0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3d8c4-ec34-473f-9078-fd515eded9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4384964-88b0-4e2c-ab55-ce6390a581dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
