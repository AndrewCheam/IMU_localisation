{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfee79c-a794-42de-9ca2-aaf44909037c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This notebook allows for training and testing that is related to the OXIOD dataset. \n",
    "\n",
    "## Tests done so far:\n",
    "\n",
    "Trained on individual domain training list, and tested on the testing list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d6658b-b44e-404c-8534-ccbcdcb6714d",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd778b87-f5d7-44b7-920a-50d6f11f4108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://192.168.16.2:8080/root/pypi/+simple/, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.6.1)\n",
      "Requirement already satisfied: protobuf>=4.22.3 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (4.23.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.22.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://192.168.16.2:8080/root/pypi/+simple/, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: numpy-quaternion in /usr/local/lib/python3.8/dist-packages (2022.4.3)\n",
      "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.8/dist-packages (from numpy-quaternion) (1.22.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://192.168.16.2:8080/root/pypi/+simple/, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.22.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "! pip install tensorboardX\n",
    "! pip install numpy-quaternion\n",
    "! pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e389f0a2-0051-416c-983f-000c95536884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from os import path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import math\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy.interpolate import interp1d\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_Oxiod import *\n",
    "from transformations import *\n",
    "from metric import compute_ate_rte\n",
    "from model_resnet1d import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4970514b-4134-456e-8bcd-ba85676559df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "\n",
    "#Paths to different files\n",
    "args.type = 'resnet'\n",
    "args.root_dir = '/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset/handheld'\n",
    "args.train_list = osp.join(args.root_dir, 'Train.txt')\n",
    "args.val_list = osp.join(args.root_dir, 'Validation.txt')\n",
    "args.test_list = osp.join(args.root_dir, 'Test.txt')\n",
    "args.out_dir = osp.join(args.root_dir, args.type + '_outputs')\n",
    "args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "\n",
    "\n",
    "args.test_path = None\n",
    "args.cache_path = None\n",
    "args.continue_from = None\n",
    "args.transfer_from = None\n",
    "\n",
    "\n",
    "# Params to tune for neural network\n",
    "args.mode = \"train\"\n",
    "args.step_size = 10\n",
    "args.window_size = 200\n",
    "args.lr = 1e-04\n",
    "args.batch_size = 256\n",
    "args.epochs = 80\n",
    "args.freeze_params = False\n",
    "\n",
    "# miscallaneous\n",
    "args.arch = \"resnet18\"\n",
    "args.cpu = False\n",
    "args.run_ekf = False\n",
    "args.fast_test = False\n",
    "\n",
    "# Plots and animation\n",
    "args.show_plot = True\n",
    "args.saveAnim = True\n",
    "\n",
    "# Smoothing feature and targets\n",
    "args.feature_sigma = 2\n",
    "args.target_sigma = 2\n",
    "\n",
    "np.set_printoptions(formatter={'all': lambda x: '{:.6f}'.format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255f8400-9ad7-4a34-afbf-a46f0877aef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_input_channel, _output_channel = 6, 2\n",
    "_fc_config = {'fc_dim': 512, 'in_dim': 4, 'dropout': 0.5, 'trans_planes': 128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cbbd5ff-4115-4a68-b111-51bbda5aac0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_test(network, data_loader, device, eval_mode=True):\n",
    "    targets_all = []\n",
    "    preds_all = []\n",
    "    if eval_mode:\n",
    "        network.eval()\n",
    "    for bid, (feat, targ, _, _) in enumerate(data_loader):\n",
    "        pred = network(feat.to(device)).cpu().detach().numpy()\n",
    "        targets_all.append(targ.detach().numpy())\n",
    "        preds_all.append(pred)\n",
    "    targets_all = np.concatenate(targets_all, axis=0)\n",
    "    preds_all = np.concatenate(preds_all, axis=0)\n",
    "    return targets_all, preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd160cd3-0d50-4f7d-a1cd-c3750fcf4e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_summary(writer, loss, step, mode):\n",
    "    names = '{0}_loss/loss_x,{0}_loss/loss_y,{0}_loss/loss_z,{0}_loss/loss_sin,{0}_loss/loss_cos'.format(\n",
    "        mode).split(',')\n",
    "\n",
    "    for i in range(loss.shape[0]):\n",
    "        writer.add_scalar(names[i], loss[i], step)\n",
    "    writer.add_scalar('{}_loss/avg'.format(mode), np.mean(loss), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a6eae8-b9d1-4faa-b72d-e0bf8bdfdbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(root_dir, data_list, args, **kwargs):\n",
    "    mode = kwargs.get('mode', 'train')\n",
    "\n",
    "    random_shift, shuffle, transforms, grv_only = 0, False, None, False\n",
    "    if mode == 'train':\n",
    "        random_shift = args.step_size // 2\n",
    "        shuffle = True\n",
    "        transforms = RandomHoriRotate(math.pi * 2)\n",
    "    elif mode == 'val':\n",
    "        shuffle = True\n",
    "    elif mode == 'test':\n",
    "        shuffle = False\n",
    "        grv_only = True\n",
    "\n",
    "    seq_type = OxfordGlobSpeedSequence\n",
    "    dataset = StridedSequenceDataset(seq_type, root_dir, data_list, args.cache_path, args.step_size, args.window_size, shuffle = shuffle, \n",
    "                                     grv_only=grv_only, transforms = transforms, random_shift = random_shift)\n",
    "    print(f'step_size: {dataset.step_size}, window_size: {dataset.window_size}')\n",
    "    global _input_channel, _output_channel\n",
    "    _input_channel, _output_channel = dataset.feature_dim, dataset.target_dim\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_dataset_from_list(root_dir, list_path, args, **kwargs):\n",
    "    with open(list_path) as f:\n",
    "        data_list = [s.strip().split(',' or ' ')[0] for s in f.readlines() if len(s) > 0 and s[0] != '#']\n",
    "    return get_dataset(root_dir, data_list, args, **kwargs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b29b8c2a-028a-4ae8-a3bf-c52c8b6709d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recon_traj_with_preds(dataset, preds, seq_id=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Reconstruct trajectory with predicted global velocities.\n",
    "    \"\"\"\n",
    "    ts = dataset.ts[seq_id]\n",
    "    ind = np.array([i[1] for i in dataset.index_map if i[0] == seq_id], dtype=np.int32) # Gets an array of frame IDs which correspond to the sequence\n",
    "    #dts = 0.01\n",
    "    dts = np.mean(ts[ind[1:]] - ts[ind[:-1]])\n",
    "\n",
    "    pos = np.zeros([preds.shape[0] + 2, 2])\n",
    "    # initial position using first position value\n",
    "    pos[0] = dataset.gt_pos[seq_id][0, :2]\n",
    "    \n",
    "    # the intermediate positions using the time interval and adding to initial position\n",
    "    pos[1:-1] = np.cumsum(preds[:, :2] * dts, axis=0) + pos[0]\n",
    "    pos[-1] = pos[-2]\n",
    "    \n",
    "    # This does interpolation because we do not have positions for every timestep. [ts[0] +/- 1e-06] corresponds to the end with an additional small value\n",
    "    ts_ext = np.concatenate([[ts[0] - 1e-06], ts[ind], [ts[-1] + 1e-06]], axis=0)\n",
    "    pos = interp1d(ts_ext, pos, axis=0)(ts)\n",
    "    # print(f'pos shape final: {pos}')\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8323cc5-e083-4291-804e-ef4a3f9f15f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_config(args):\n",
    "    if args.out_dir:\n",
    "        with open(osp.join(args.out_dir, 'config.json'), 'w') as f:\n",
    "            json.dump(vars(args), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ecb3f1-6c6c-4c2b-83da-5a0fd8e2fbec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def showAnimation(video_path):\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    video_widget = widgets.Video.from_file(video_path)\n",
    "    video_widget.controls = True\n",
    "    video_widget.autoplay = True\n",
    "    display(video_widget)\n",
    "\n",
    "def plotTrajectory(true_x_values, true_y_values, pred_x_values, pred_y_values):    \n",
    "    plt.figure('{}'.format(\"Trajectory\"), figsize=(16, 9))\n",
    "\n",
    "    length = len(true_x_values)\n",
    "    multiplier = 50\n",
    "    # creating a blank window\n",
    "    # for the animation\n",
    "    fig = plt.figure()\n",
    "    min_x_value = np.min([np.min(true_x_values), np.min(pred_x_values)])\n",
    "    max_x_value = np.max([np.max(true_x_values), np.max(pred_x_values)])\n",
    "    min_y_value = np.min([np.min(true_y_values), np.min(pred_y_values)])\n",
    "    max_y_value = np.max([np.max(true_y_values), np.max(pred_y_values)])\n",
    "    \n",
    "    \n",
    "    axis = plt.axes(xlim =(min_x_value, max_x_value), ylim =(min_y_value, max_y_value))\n",
    "    \n",
    "    line1, = axis.plot([], [], 'b', label='Line 1')\n",
    "    line2, = axis.plot([], [], 'r', label='Line 2')\n",
    "\n",
    "    def init():\n",
    "        line1.set_data([], [])\n",
    "        return line1,\n",
    "    def init():\n",
    "        line2.set_data([], [])\n",
    "        return line2,\n",
    "\n",
    "    # initializing empty values\n",
    "    # for x and y co-ordinates\n",
    "    true_xdata, true_ydata, pred_xdata, pred_ydata = [], [], [], []\n",
    "\n",
    "    # animation function\n",
    "    def animate(i):\n",
    "        true_x = true_x_values[i * multiplier]\n",
    "        true_y = true_y_values[i * multiplier]\n",
    "        pred_x = pred_x_values[i * multiplier]\n",
    "        pred_y = pred_y_values[i * multiplier]\n",
    "        \n",
    "        true_xdata.append(true_x)\n",
    "        true_ydata.append(true_y)\n",
    "        pred_xdata.append(pred_x)\n",
    "        pred_ydata.append(pred_y)\n",
    "        \n",
    "        line1.set_data(true_xdata, true_ydata)\n",
    "        line2.set_data(pred_xdata, pred_ydata)\n",
    "\n",
    "        return line1, line2\n",
    "\n",
    "    # calling the animation function\t\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func = init, frames = int(length/multiplier), interval = 0.01, blit = True)\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd833d0f-2463-4671-b2ef-e9118308c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, **kwargs):\n",
    "    # Loading data\n",
    "    start_t = time.time()\n",
    "    train_dataset = get_dataset_from_list(args.root_dir, args.train_list, args,  mode='train')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    end_t = time.time()\n",
    "    print('Training set loaded. Feature size: {}, target size: {}. Time usage: {:.3f}s'.format(\n",
    "        train_dataset.feature_dim, train_dataset.target_dim, end_t - start_t))\n",
    "    \n",
    "    val_dataset, val_loader = None, None\n",
    "    if args.val_list is not None:\n",
    "        val_dataset = get_dataset_from_list(args.root_dir, args.val_list, args, mode='val')\n",
    "        val_loader = DataLoader(val_dataset, batch_size=512, shuffle=True)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() and not args.cpu else 'cpu')\n",
    "\n",
    "    summary_writer = None\n",
    "    \n",
    "    if args.out_dir is not None:\n",
    "        if not osp.isdir(args.out_dir):\n",
    "            os.makedirs(args.out_dir)\n",
    "        write_config(args)\n",
    "            \n",
    "        if not osp.isdir(osp.join(args.out_dir, 'checkpoints')):\n",
    "            os.makedirs(osp.join(args.out_dir, 'checkpoints'))\n",
    "        if not osp.isdir(osp.join(args.out_dir, 'logs')):\n",
    "            os.makedirs(osp.join(args.out_dir, 'logs'))\n",
    "\n",
    "    global _fc_config\n",
    "    _fc_config['in_dim'] = args.window_size // 32 + 1\n",
    "    network = ResNet1D(_input_channel, _output_channel, BasicBlock1D, [2, 2, 2, 2],\n",
    "                           base_plane=64, output_block=FCOutputModule, kernel_size=3, **_fc_config)\n",
    "    network.to(device)\n",
    "\n",
    "    \n",
    "    \n",
    "    print('Number of train samples: {}'.format(len(train_dataset)))\n",
    "    if val_dataset:\n",
    "        print('Number of val samples: {}'.format(len(val_dataset)))\n",
    "    total_params = network.get_num_params()\n",
    "    print('Total number of parameters: ', total_params)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(network.parameters(), args.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, verbose=True, eps=1e-12)\n",
    "\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # Continues from last model that was trained\n",
    "    if args.continue_from is not None and osp.exists(args.continue_from):\n",
    "        checkpoints = torch.load(args.continue_from)\n",
    "        start_epoch = checkpoints.get('epoch', 0)\n",
    "        network.load_state_dict(checkpoints.get('model_state_dict'))\n",
    "        optimizer.load_state_dict(checkpoints.get('optimizer_state_dict'))\n",
    "        \n",
    "    # Transfer learns from model that was trained\n",
    "    if args.transfer_from is not None and osp.exists(args.transfer_from):\n",
    "        checkpoints = torch.load(args.transfer_from)\n",
    "        network.load_state_dict(checkpoints.get('model_state_dict'))    \n",
    "        print('loaded model from', args.transfer_from)\n",
    "        if args.freeze_params:\n",
    "            for param in network.parameters():\n",
    "                param.requires_grad = False\n",
    "        network.reset_output_block(BasicBlock1D, _output_channel, **_fc_config)\n",
    "        optimizer = torch.optim.Adam(network.parameters(), args.lr)\n",
    "        total_params = network.get_num_params()\n",
    "        print('Total number of parameters: ', total_params)\n",
    "        network.to(device)\n",
    "        network.train()\n",
    "        \n",
    "    \n",
    "    step = 0\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    print('Start from epoch {}'.format(start_epoch))\n",
    "    total_epoch = start_epoch\n",
    "    train_losses_all, val_losses_all = [], []\n",
    "\n",
    "    # Get the initial loss, this should be with the randomised weights\n",
    "    init_train_targ, init_train_pred = run_test(network, train_loader, device, eval_mode=False)\n",
    "\n",
    "    init_train_loss = np.mean((init_train_targ - init_train_pred) ** 2, axis=0)\n",
    "    train_losses_all.append(np.mean(init_train_loss))\n",
    "    print('-------------------------')\n",
    "    print('Init: average loss: {}/{:.6f}'.format(init_train_loss, train_losses_all[-1]))\n",
    "    if summary_writer is not None:\n",
    "        add_summary(summary_writer, init_train_loss, 0, 'train')\n",
    "\n",
    "    if val_loader is not None:\n",
    "        init_val_targ, init_val_pred = run_test(network, val_loader, device)\n",
    "        init_val_loss = np.mean((init_val_targ - init_val_pred) ** 2, axis=0)\n",
    "        val_losses_all.append(np.mean(init_val_loss))\n",
    "        print('Validation loss: {}/{:.6f}'.format(init_val_loss, val_losses_all[-1]))\n",
    "        if summary_writer is not None:\n",
    "            add_summary(summary_writer, init_val_loss, 0, 'val')\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, args.epochs):\n",
    "            start_t = time.time()\n",
    "            network.train()\n",
    "            train_outs, train_targets = [], []\n",
    "            for batch_id, (feat, targ, _, _) in enumerate(train_loader):\n",
    "                feat, targ = feat.to(device), targ.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                pred = network(feat)\n",
    "                train_outs.append(pred.cpu().detach().numpy())\n",
    "                train_targets.append(targ.cpu().detach().numpy())\n",
    "                loss = criterion(pred, targ)\n",
    "                loss = torch.mean(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                step += 1\n",
    "            train_outs = np.concatenate(train_outs, axis=0)\n",
    "            train_targets = np.concatenate(train_targets, axis=0)\n",
    "            train_losses = np.average((train_outs - train_targets) ** 2, axis=0)\n",
    "\n",
    "            end_t = time.time()\n",
    "            print('-------------------------')\n",
    "            print('Epoch {}, time usage: {:.3f}s, average loss: {}/{:.6f}'.format(\n",
    "                epoch, end_t - start_t, train_losses, np.average(train_losses)))\n",
    "            train_losses_all.append(np.average(train_losses))\n",
    "\n",
    "            if summary_writer is not None:\n",
    "                add_summary(summary_writer, train_losses, epoch + 1, 'train')\n",
    "                summary_writer.add_scalar('optimizer/lr', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "            #if we have a validation dataset, checkpoint is saved based on the best validation loss\n",
    "            if val_loader is not None:\n",
    "                network.eval()\n",
    "                val_outs, val_targets = run_test(network, val_loader, device)\n",
    "                val_losses = np.average((val_outs - val_targets) ** 2, axis=0)\n",
    "                avg_loss = np.average(val_losses)\n",
    "                print('Validation loss: {}/{:.6f}'.format(val_losses, avg_loss))\n",
    "                scheduler.step(avg_loss)\n",
    "                if summary_writer is not None:\n",
    "                    add_summary(summary_writer, val_losses, epoch + 1, 'val')\n",
    "                val_losses_all.append(avg_loss)\n",
    "                if avg_loss < best_val_loss:\n",
    "                    best_val_loss = avg_loss\n",
    "                    if args.out_dir and osp.isdir(args.out_dir):\n",
    "                        model_path = osp.join(args.out_dir, 'checkpoints', 'checkpoint_%d.pt' % epoch)\n",
    "                        torch.save({'model_state_dict': network.state_dict(),\n",
    "                                    'epoch': epoch,\n",
    "                                    'optimizer_state_dict': optimizer.state_dict()}, model_path)\n",
    "                        print('Model saved to ', model_path)\n",
    "            else:\n",
    "                if args.out_dir is not None and osp.isdir(args.out_dir):\n",
    "                    model_path = osp.join(args.out_dir, 'checkpoints', 'checkpoint_%d.pt' % epoch)\n",
    "                    torch.save({'model_state_dict': network.state_dict(),\n",
    "                                'epoch': epoch,\n",
    "                                'optimizer_state_dict': optimizer.state_dict()}, model_path)\n",
    "                    print('Model saved to ', model_path)\n",
    "\n",
    "            total_epoch = epoch\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('-' * 60)\n",
    "        print('Early terminate')\n",
    "\n",
    "    print('Training complete')\n",
    "    if args.out_dir:\n",
    "        model_path = osp.join(args.out_dir, 'checkpoints', 'checkpoint_latest.pt')\n",
    "        torch.save({'model_state_dict': network.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'epoch': total_epoch}, model_path)\n",
    "        print('Checkpoint saved to ', model_path)\n",
    "\n",
    "    return train_losses_all, val_losses_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a37f5bf6-e08c-485f-9c36-9bd611514d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_sequence(args):\n",
    "    args.mode = 'test'\n",
    "    if args.test_path is not None:\n",
    "        if args.test_path[-1] == '/':\n",
    "            args.test_path = args.test_path[:-1]\n",
    "        root_dir = osp.split(args.test_path)[0]\n",
    "        test_data_list = [osp.split(args.test_path)[1]]\n",
    "    elif args.test_list is not None:\n",
    "        root_dir = args.root_dir\n",
    "        with open(args.test_list) as f:\n",
    "            test_data_list = [s.strip().split(',' or ' ')[0] for s in f.readlines() if len(s) > 0 and s[0] != '#']\n",
    "    else:\n",
    "        raise ValueError('Either test_path or test_list must be specified.')\n",
    "\n",
    "    if args.out_dir is not None and not osp.isdir(args.out_dir):\n",
    "        os.makedirs(args.out_dir)\n",
    "\n",
    "    if not osp.isdir(osp.join(args.out_dir, 'Videos')) or not osp.isdir(osp.join(args.out_dir, 'Graphs')):\n",
    "        os.makedirs(osp.join(args.out_dir, 'Videos'))\n",
    "        os.makedirs(osp.join(args.out_dir, 'Graphs'))\n",
    "\n",
    "    if not torch.cuda.is_available() or args.cpu:\n",
    "        device = torch.device('cpu')\n",
    "        checkpoint = torch.load(args.model_path, map_location=lambda storage, location: storage)\n",
    "    else:\n",
    "        device = torch.device('cuda:0')\n",
    "        checkpoint = torch.load(args.model_path)\n",
    "\n",
    "    # Load the first sequence to update the input and output size\n",
    "    _ = get_dataset(root_dir, [test_data_list[0]], args)\n",
    "\n",
    "    global _fc_config\n",
    "    _fc_config['in_dim'] = args.window_size // 32 + 1\n",
    "    network = ResNet1D(_input_channel, _output_channel, BasicBlock1D, [2, 2, 2, 2],\n",
    "                           base_plane=64, output_block=FCOutputModule, kernel_size=3, **_fc_config)\n",
    "\n",
    "    network.load_state_dict(checkpoint['model_state_dict'])\n",
    "    network.eval().to(device)\n",
    "    print('Model {} loaded to device {}.'.format(args.model_path, device))\n",
    "\n",
    "    preds_seq, targets_seq, losses_seq, ate_all, rte_all = [], [], [], [], []\n",
    "    traj_lens = []\n",
    "\n",
    "    pred_per_min = 200 * 60\n",
    "\n",
    "    for data in test_data_list:\n",
    "        seq_dataset = get_dataset(root_dir, [data], args, mode='test')\n",
    "        seq_loader = DataLoader(seq_dataset, batch_size=1024, shuffle=False)\n",
    "        ind = np.array([i[1] for i in seq_dataset.index_map if i[0] == 0], dtype=np.int32)\n",
    "\n",
    "        targets, preds = run_test(network, seq_loader, device, True)\n",
    "        losses = np.mean((targets - preds) ** 2, axis=0)\n",
    "        preds_seq.append(preds)\n",
    "        targets_seq.append(targets)\n",
    "        losses_seq.append(losses)\n",
    "        \n",
    "        pos_pred = recon_traj_with_preds(seq_dataset, preds)[:, :2]\n",
    "        pos_gt = seq_dataset.gt_pos[0][:, :2]\n",
    "\n",
    "        # Calculates length of a trajectory and appends into list\n",
    "        traj_lens.append(np.sum(np.linalg.norm(pos_gt[1:] - pos_gt[:-1], axis=1)))\n",
    "        ate, rte = compute_ate_rte(pos_pred, pos_gt, pred_per_min)\n",
    "        ate_all.append(ate)\n",
    "        rte_all.append(rte)\n",
    "        pos_cum_error = np.linalg.norm(pos_pred - pos_gt, axis=1)\n",
    "\n",
    "        print('Sequence {}, loss {} / {}, ate {:.6f}, rte {:.6f}'.format(data, losses, np.mean(losses), ate, rte))\n",
    "\n",
    "        targ_names = ['vx', 'vy']\n",
    "        kp = 2\n",
    "        \n",
    "        \n",
    "        if args.out_dir is not None and osp.isdir(args.out_dir) and args.saveAnim:\n",
    "            video_path = osp.join(args.out_dir, 'Videos/' + ''.join(data.split('/')) +'_Trajectory.mp4')\n",
    "            animation = plotTrajectory(pos_gt[:, 0], pos_gt[:, 1], pos_pred[:, 0], pos_pred[:, 1])\n",
    "            animation.save(video_path, writer = 'ffmpeg', fps = 50, bitrate = 700)\n",
    "            showAnimation(video_path)\n",
    "\n",
    "        plt.figure('{}'.format(data), figsize=(16, 9))\n",
    "        plt.subplot2grid((kp, 2), (0, 0), rowspan=kp - 1)\n",
    "        plt.plot(pos_pred[:, 0], pos_pred[:, 1])\n",
    "        plt.plot(pos_gt[:, 0], pos_gt[:, 1])\n",
    "        plt.title(data)\n",
    "        plt.axis('equal')\n",
    "        plt.legend(['Predicted', 'Ground truth'])\n",
    "        plt.subplot2grid((kp, 2), (kp - 1, 0))\n",
    "        plt.plot(pos_cum_error)\n",
    "        plt.legend(['ATE:{:.3f}, RTE:{:.3f}'.format(ate_all[-1], rte_all[-1])])\n",
    "        for i in range(kp):\n",
    "            plt.subplot2grid((kp, 2), (i, 1))\n",
    "            plt.plot(ind, preds[:, i])\n",
    "            plt.plot(ind, targets[:, i])\n",
    "            plt.legend(['Predicted', 'Ground truth'])\n",
    "            plt.title('{}, error: {:.6f}'.format(targ_names[i], losses[i]))\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if args.out_dir is not None and osp.isdir(args.out_dir):\n",
    "            np.save(osp.join(args.out_dir, 'Graphs/'+''.join(data.split('/')) + '_gsn.npy'),\n",
    "                    np.concatenate([pos_pred[:, :2], pos_gt[:, :2]], axis=1))\n",
    "            plt.savefig(osp.join(args.out_dir, 'Graphs/'+''.join(data.split('/')) + '_gsn.png'))\n",
    "        \n",
    "        if args.show_plot:\n",
    "            plt.show()\n",
    "        plt.close('all')   \n",
    "\n",
    "    losses_seq = np.stack(losses_seq, axis=0)\n",
    "    losses_avg = np.mean(losses_seq, axis=1)\n",
    "    # Export a csv file\n",
    "    seq_name = root_dir.split('/')[-1]\n",
    "    model_type = ''\n",
    "    if 'txLearning_outputs' in args.model_path:\n",
    "        model_type = 'TX_'\n",
    "    if args.out_dir is not None and osp.isdir(args.out_dir):\n",
    "        with open(osp.join(args.out_dir, 'losses.csv'), 'w') as f:\n",
    "            if losses_seq.shape[1] == 2:\n",
    "                f.write(f'seq,vx,vy,avg,{model_type}ate,{model_type}rte\\n')\n",
    "            else:\n",
    "                f.write(f'seq,vx,vy,vz,avg,{model_type}ate,{model_type}rte\\n')\n",
    "            for i in range(losses_seq.shape[0]):\n",
    "                f.write(seq_name+'{},'.format(test_data_list[i]))\n",
    "                for j in range(losses_seq.shape[1]):\n",
    "                    f.write('{:.6f},'.format(losses_seq[i][j]))\n",
    "                f.write('{:.6f},{:6f},{:.6f}\\n'.format(losses_avg[i], ate_all[i], rte_all[i]))\n",
    "\n",
    "    print('----------\\nOverall loss: {}/{}, avg ATE:{}, avg RTE:{}'.format(\n",
    "        np.average(losses_seq, axis=0), np.average(losses_avg), np.mean(ate_all), np.mean(rte_all)))\n",
    "    return losses_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ee920-c813-4f9e-ab40-6274660679e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training and testing with optimal training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca3a94f5-cc7e-4f28-9dfc-8f5aba20590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handbag\n",
      "step_size: 10, window_size: 200\n",
      "Number of train samples: 27350\n",
      "handheld\n",
      "step_size: 10, window_size: 200\n",
      "Number of train samples: 50184\n",
      "pocket\n",
      "step_size: 10, window_size: 200\n",
      "Number of train samples: 32205\n",
      "running\n",
      "step_size: 10, window_size: 200\n",
      "Number of train samples: 24998\n",
      "slow walking\n",
      "step_size: 10, window_size: 200\n",
      "Number of train samples: 30234\n",
      "trolley\n",
      "step_size: 10, window_size: 200\n",
      "Number of train samples: 33308\n",
      "large scale\n",
      "step_size: 10, window_size: 200\n",
      "Number of train samples: 30082\n"
     ]
    }
   ],
   "source": [
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "for data in data_path_list:\n",
    "    print(data)\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.train_list = osp.join(args.root_dir, 'Train.txt')\n",
    "    train_dataset = get_dataset_from_list(args.root_dir, args.train_list, args,  mode='train')\n",
    "    print('Number of train samples: {}'.format(len(train_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2ce3f-4f08-475c-9798-e296e7d28756",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training and Testing within its own domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89ca12-28d8-4f3f-840e-02adef33dc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "i = 1\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "fig.tight_layout()\n",
    "for data in data_path_list:\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.train_list = osp.join(args.root_dir, 'Train-small.txt')\n",
    "    args.val_list = osp.join(args.root_dir, 'Validation.txt')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "    args.out_dir = osp.join(args.root_dir, args.type + '_outputs')\n",
    "    train_losses, val_losses = train(args)\n",
    "    plt.subplot(math.ceil(len(data_path_list) / 2), 2 , i)\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.title(data+' training loss')\n",
    "    plt.legend(['train_loss', 'val_loss'])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44639833-bb24-4bb3-af01-e085ad24a8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.feature_sigma = 2\n",
    "args.target_sigma = -1\n",
    "args.saveAnim = False\n",
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "for data in data_path_list:\n",
    "    print(f'=============================================================================outputs for {data} ==============================================================')\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.test_list = osp.join(args.root_dir, 'Test.txt')\n",
    "    args.out_dir = osp.join(args.root_dir, 'outputs')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "    test_sequence(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28685a55-4965-4e7d-a86b-a7455440be68",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transfer Learning using pre-trained ronin resnet model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17702904-1ee1-4b53-9233-3cd3d98c596f",
   "metadata": {},
   "source": [
    "##### The naive use of the ronin pretrained model yields extremely poor results on all of the domains in the OXIOD dataset. Hence we try using transfer learning to see if the model is able to reuse the weights learned from a larger dataset (ronin) and learn from the smaller domain's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77329cd2-f084-4433-bf40-1f91f346d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "i = 1\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "fig.tight_layout()\n",
    "for data in data_path_list:\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.train_list = osp.join(args.root_dir, 'Train.txt')\n",
    "    args.val_list = osp.join(args.root_dir, 'Validation.txt')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "    args.out_dir = osp.join(args.root_dir, 'txLearning_outputs')\n",
    "    args.transfer_from = '/home/jovyan/ronin/PreTrained_Models/ronin_resnet/ronin_resnet/checkpoint_gsn_latest.pt'\n",
    "    train_losses, val_losses = train(args)\n",
    "    plt.subplot(math.ceil(len(data_path_list) / 2), 2 , i)\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.title(data+' training loss')\n",
    "    plt.legend(['train_loss', 'val_loss'])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc73609-bda4-4226-bc80-c4394f0a50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.saveAnim = True\n",
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "for data in data_path_list:\n",
    "    print(f'=============================================================================outputs for {data} ==============================================================')\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.test_list = osp.join(args.root_dir, 'Test.txt')\n",
    "    args.out_dir = osp.join(args.root_dir, 'txLearning_outputs')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "    test_sequence(args)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d9869-2f9a-4e68-8e3f-35f29f260ddf",
   "metadata": {},
   "source": [
    "## Combine all outputs to view results clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6cf68f-b3c7-4a91-902b-932f8c822ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "results_df = pd.DataFrame(columns = ['seq', 'ate', 'rte', 'TX_ate', 'TX_rte'])\n",
    "for data in data_path_list:\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    txData = pd.read_csv(osp.join(args.root_dir, 'txLearning_outputs/losses.csv'))[['TX_ate', 'TX_rte']]\n",
    "    Data = pd.read_csv(osp.join(args.root_dir, 'outputs/losses.csv'))[['seq', 'ate', 'rte']]\n",
    "    combined = pd.concat([Data, txData], axis = 1)\n",
    "    results_df = pd.concat([results_df, combined], axis = 0)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "results_df.plot(x='seq', y=['ate', 'rte', 'TX_ate', 'TX_rte'], kind='bar', ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1804f293-68b7-4101-a2bd-a7e6e97b0643",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training and testing with small training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2cf3d-1015-4f9e-9e5e-ce0859bbe95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "for data in data_path_list:\n",
    "    print(data)\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.train_list = osp.join(args.root_dir, 'Train.txt')\n",
    "    train_dataset = get_dataset_from_list(args.root_dir, args.train_list, args,  mode='train')\n",
    "    print('Number of train samples: {}'.format(len(train_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c4af4-a57e-400b-8735-12789a331568",
   "metadata": {},
   "source": [
    "## Training model on its own domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006dcfd8-1f1e-4cf3-8600-9285cd45a502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "i = 1\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "fig.tight_layout()\n",
    "for data in data_path_list:\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.train_list = osp.join(args.root_dir, 'Train-small.txt')\n",
    "    args.val_list = osp.join(args.root_dir, 'Validation.txt')\n",
    "    args.out_dir = osp.join(args.root_dir, 'small_outputs')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt') \n",
    "    train_losses, val_losses = train(args)\n",
    "    plt.subplot(math.ceil(len(data_path_list) / 2), 2 , i)\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.title(data+' training loss')\n",
    "    plt.legend(['train_loss', 'val_loss'])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff9f76-678f-4e11-81aa-7b09da6e351c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.feature_sigma = 2\n",
    "args.target_sigma = -1\n",
    "args.saveAnim = False\n",
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "for data in data_path_list:\n",
    "    print(f'=============================================================================outputs for {data} ==============================================================')\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.test_list = osp.join(args.root_dir, 'Test.txt')\n",
    "    args.out_dir = osp.join(args.root_dir, 'small_outputs')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "    test_sequence(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89938378-f4a1-4c1e-b3ce-43d51b020460",
   "metadata": {},
   "source": [
    "## Transfer learning by pretrained ronin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569e43e-0340-4d97-873c-cbae845a6fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "i = 1\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "fig.tight_layout()\n",
    "for data in data_path_list:\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.train_list = osp.join(args.root_dir, 'Train-small.txt')\n",
    "    args.val_list = osp.join(args.root_dir, 'Validation.txt')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "    args.out_dir = osp.join(args.root_dir, 'small_txLearning_outputs')\n",
    "    args.transfer_from = '/home/jovyan/ronin/PreTrained_Models/ronin_resnet/ronin_resnet/checkpoint_gsn_latest.pt'\n",
    "    train_losses, val_losses = train(args)\n",
    "    plt.subplot(math.ceil(len(data_path_list) / 2), 2 , i)\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.title(data+' training loss')\n",
    "    plt.legend(['train_loss', 'val_loss'])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75183445-5866-4c08-9240-4c1b6b2a5565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.saveAnim = False\n",
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "for data in data_path_list:\n",
    "    print(f'=============================================================================outputs for {data} ==============================================================')\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    args.test_list = osp.join(args.root_dir, 'Test.txt')\n",
    "    args.out_dir = osp.join(args.root_dir, 'small_txLearning_outputs')\n",
    "    args.model_path = osp.join(args.out_dir, 'checkpoints/checkpoint_latest.pt')\n",
    "    test_sequence(args)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0e623-5160-473e-b0aa-bb1e92ce6521",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combine all outputs to see data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fa1bd-e3b1-4132-889a-8c131fa80022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path_list = ['handbag', 'handheld', 'pocket', 'running', 'slow walking', 'trolley', 'large scale']\n",
    "results_df = pd.DataFrame(columns = ['seq', 'ate', 'rte', 'TX_ate', 'TX_rte'])\n",
    "for data in data_path_list:\n",
    "    args.root_dir = osp.join('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset', data)\n",
    "    txData = pd.read_csv(osp.join(args.root_dir, 'small_txLearning_outputs/losses.csv'))[['TX_ate', 'TX_rte']]\n",
    "    Data = pd.read_csv(osp.join(args.root_dir, 'small_outputs/losses.csv'))[['seq', 'ate', 'rte']]\n",
    "    combined = pd.concat([Data, txData], axis = 1)\n",
    "    results_df = pd.concat([results_df, combined], axis = 0)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "results_df.plot(x='seq', y=['ate', 'rte', 'TX_ate', 'TX_rte'], kind='bar', ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f939d8-fabb-41fd-95ad-a3940de079b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualisation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d686a25-3be0-4bd7-808f-89d43ca869aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "seq_dataset = get_dataset('/home/jovyan/localisation_datasets/Oxford Inertial Odometry Dataset/handbag', ['data1/combined1.csv'], args, mode='train')\n",
    "seq_loader = DataLoader(seq_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992d23d-bb75-423f-8768-c02ae7579f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ResNet1D(_input_channel, _output_channel, BasicBlock1D, [2, 2, 2, 2],\n",
    "                           base_plane=64, output_block=FCOutputModule, kernel_size=3, **_fc_config)\n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "\n",
    "for bid, (feat, targ, _, _) in enumerate(seq_loader):\n",
    "    print(feat.shape)\n",
    "    torch.onnx.export(network, feat, \"model.onnx\", input_names=input_names, output_names=output_names)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
